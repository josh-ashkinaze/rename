{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T21:07:23.066016Z",
     "start_time": "2024-11-25T21:07:23.021679Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial import distance\n",
    "import numpy as np \n",
    "import json\n"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:07:26.572391Z",
     "start_time": "2024-11-25T21:07:26.564661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial import distance\n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "\n",
    "def open_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def parse_question(q):\n",
    "    import numpy as np \n",
    "    qid = q['question_id']\n",
    "    q_text = q['question']\n",
    "    harris_responses = q['responses']['harris_supporters']\n",
    "    trump_responses = q['responses']['trump_supporters']\n",
    "    \n",
    "    harris_responses_values = list(harris_responses.values())\n",
    "    trump_responses_values = list(trump_responses.values())\n",
    "    \n",
    "    # # delete refued\n",
    "    try:\n",
    "        del harris_responses['refused']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del trump_responses['refused']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    harris_responses_normalized = [i/sum(harris_responses_values) for i in harris_responses_values]\n",
    "    trump_responses_normalized = [i/sum(trump_responses_values) for i in trump_responses_values]\n",
    "    \n",
    "    \n",
    "    domain = q['domain']\n",
    "    \n",
    "    data = {\n",
    "        'qid': qid,\n",
    "        'question': q_text,\n",
    "        'harris_responses': harris_responses,\n",
    "        'trump_responses': trump_responses,\n",
    "        'harris_responses_values': harris_responses_values,\n",
    "        'trump_responses_values': trump_responses_values,\n",
    "        'harris_responses_normalized': harris_responses_normalized,\n",
    "        'trump_responses_normalized': trump_responses_normalized,\n",
    "        'harris_responses_normalized_sum': sum(harris_responses_normalized),\n",
    "        'trump_responses_normalized_sum': sum(trump_responses_normalized),\n",
    "        'jsd': compute_array_metrics(harris_responses_normalized, trump_responses_normalized),\n",
    "        'harris_entropy': -sum([i * np.log(i) for i in harris_responses_normalized]),\n",
    "        'trump_entropy': -sum([i * np.log(i) for i in trump_responses_normalized]),\n",
    "        'domain': domain\n",
    "    }\n",
    "    data['avg_entropy'] = (data['harris_entropy'] + data['trump_entropy'])/2\n",
    "    if data['jsd'] is None:\n",
    "        print(\"Could not print JSD for this\")\n",
    "        print(data)\n",
    "        print()\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def compute_array_metrics(ar1, ar2):\n",
    "    try:\n",
    "        return distance.jensenshannon(ar1, ar2)\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    \n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "a = {'us_exceptionalism': {'question_id': 'USEXCEPT_W146',\n",
    "  'question': 'Which of these statements best describes your opinion about the United States?',\n",
    "  'responses': {'all_voters': {'stands_above_all_others': 23,\n",
    "    'one_of_greatest_with_others': 56,\n",
    "    'other_countries_better': 20,\n",
    "    'refused': 1},\n",
    "   'harris_supporters': {'stands_above_all_others': 12,\n",
    "    'one_of_greatest_with_others': 60,\n",
    "    'other_countries_better': 27,\n",
    "    'refused': 0},\n",
    "   'trump_supporters': {'stands_above_all_others': 35,\n",
    "    'one_of_greatest_with_others': 53,\n",
    "    'other_countries_better': 11,\n",
    "    'refused': 1}}}}\n",
    "\n",
    "\n",
    "j = open_json('../data/raw/pew_data/merged_survey_data.json')\n",
    "\n",
    "data = []\n",
    "for key in j.keys():\n",
    "    parse_question(j[key])\n",
    "    data.append(parse_question(j[key]))\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=['jsd'])\n",
    "\n",
    "    "
   ],
   "id": "c2ce0e9657cbd058",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:07:43.499203Z",
     "start_time": "2024-11-25T21:07:43.437303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_question(q):\n",
    "    import numpy as np \n",
    "    qid = q['question_id']\n",
    "    q_text = q['question']\n",
    "    harris_responses = q['responses']['harris_supporters']\n",
    "    trump_responses = q['responses']['trump_supporters']\n",
    "    \n",
    "    harris_responses_values = list(harris_responses.values())\n",
    "    trump_responses_values = list(trump_responses.values())\n",
    "    \n",
    "    # # delete refued\n",
    "    try:\n",
    "        del harris_responses['refused']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del trump_responses['refused']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    harris_responses_normalized = [i/sum(harris_responses_values) for i in harris_responses_values]\n",
    "    trump_responses_normalized = [i/sum(trump_responses_values) for i in trump_responses_values]\n",
    "    \n",
    "    \n",
    "    domain = q['domain']\n",
    "    \n",
    "    data = {\n",
    "        'qid': qid,\n",
    "        'question': q_text,\n",
    "        'harris_responses': harris_responses,\n",
    "        'trump_responses': trump_responses,\n",
    "        'harris_responses_values': harris_responses_values,\n",
    "        'trump_responses_values': trump_responses_values,\n",
    "        'harris_responses_normalized': harris_responses_normalized,\n",
    "        'trump_responses_normalized': trump_responses_normalized,\n",
    "        'harris_responses_normalized_sum': sum(harris_responses_normalized),\n",
    "        'trump_responses_normalized_sum': sum(trump_responses_normalized),\n",
    "        'jsd': compute_array_metrics(harris_responses_normalized, trump_responses_normalized),\n",
    "        'harris_entropy': -sum([i * np.log(i) for i in harris_responses_normalized]),\n",
    "        'trump_entropy': -sum([i * np.log(i) for i in trump_responses_normalized]),\n",
    "        'domain': domain\n",
    "    }\n",
    "    data['avg_entropy'] = (data['harris_entropy'] + data['trump_entropy'])/2\n",
    "    if data['jsd'] is None:\n",
    "        print(\"Could not print JSD for this\")\n",
    "        print(data)\n",
    "        print()\n",
    "    return data\n",
    "    \n",
    "    \n",
    "def compute_array_metrics(ar1, ar2):\n",
    "    try:\n",
    "        return distance.jensenshannon(ar1, ar2)\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    \n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "a = {'us_exceptionalism': {'question_id': 'USEXCEPT_W146',\n",
    "  'question': 'Which of these statements best describes your opinion about the United States?',\n",
    "  'responses': {'all_voters': {'stands_above_all_others': 23,\n",
    "    'one_of_greatest_with_others': 56,\n",
    "    'other_countries_better': 20,\n",
    "    'refused': 1},\n",
    "   'harris_supporters': {'stands_above_all_others': 12,\n",
    "    'one_of_greatest_with_others': 60,\n",
    "    'other_countries_better': 27,\n",
    "    'refused': 0},\n",
    "   'trump_supporters': {'stands_above_all_others': 35,\n",
    "    'one_of_greatest_with_others': 53,\n",
    "    'other_countries_better': 11,\n",
    "    'refused': 1}}}}\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    "for key in j.keys():\n",
    "    parse_question(j[key])\n",
    "    data.append(parse_question(j[key]))\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=['jsd'])\n",
    "\n",
    "    "
   ],
   "id": "391af06d2bb41e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not print JSD for this\n",
      "{'qid': 'GOVTHC_W146', 'question': 'Do you think it is the responsibility of the federal government to make sure all Americans have health care coverage?', 'harris_responses': {'yes_responsibility': 91, 'no_not_responsibility': 9, 'no_involvement': 0}, 'trump_responses': {'yes_responsibility': 32, 'no_not_responsibility': 67}, 'harris_responses_values': [91, 9, 0, 0], 'trump_responses_values': [32, 67, 1], 'harris_responses_normalized': [0.91, 0.09, 0.0, 0.0], 'trump_responses_normalized': [0.32, 0.67, 0.01], 'harris_responses_normalized_sum': 1.0, 'trump_responses_normalized_sum': 1.0, 'jsd': None, 'harris_entropy': np.float64(nan), 'trump_entropy': np.float64(0.6789906421002316), 'domain': 'social_safety_net', 'avg_entropy': np.float64(nan)}\n",
      "\n",
      "Could not print JSD for this\n",
      "{'qid': 'GOVTHC_W146', 'question': 'Do you think it is the responsibility of the federal government to make sure all Americans have health care coverage?', 'harris_responses': {'yes_responsibility': 91, 'no_not_responsibility': 9, 'no_involvement': 0}, 'trump_responses': {'yes_responsibility': 32, 'no_not_responsibility': 67}, 'harris_responses_values': [91, 9, 0], 'trump_responses_values': [32, 67], 'harris_responses_normalized': [0.91, 0.09, 0.0], 'trump_responses_normalized': [0.32323232323232326, 0.6767676767676768], 'harris_responses_normalized_sum': 1.0, 'trump_responses_normalized_sum': 1.0, 'jsd': None, 'harris_entropy': np.float64(nan), 'trump_entropy': np.float64(0.6292819270155396), 'domain': 'social_safety_net', 'avg_entropy': np.float64(nan)}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/36c2knv139jfg23x561mj5xr0000gp/T/ipykernel_25473/490957296.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "  'harris_entropy': -sum([i * np.log(i) for i in harris_responses_normalized]),\n",
      "/var/folders/gc/36c2knv139jfg23x561mj5xr0000gp/T/ipykernel_25473/490957296.py:39: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  'harris_entropy': -sum([i * np.log(i) for i in harris_responses_normalized]),\n",
      "/var/folders/gc/36c2knv139jfg23x561mj5xr0000gp/T/ipykernel_25473/490957296.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  'trump_entropy': -sum([i * np.log(i) for i in trump_responses_normalized]),\n",
      "/var/folders/gc/36c2knv139jfg23x561mj5xr0000gp/T/ipykernel_25473/490957296.py:40: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  'trump_entropy': -sum([i * np.log(i) for i in trump_responses_normalized]),\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:18:58.911185Z",
     "start_time": "2024-11-25T21:18:58.736587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns \n",
    "\n",
    "def clean_label(x):\n",
    "    x = x.replace(\"_\", \" \")\n",
    "    return x.title()\n",
    "\n",
    "aggregated = df.groupby(by=['domain'])['jsd'].agg(['mean', 'std', 'median']).reset_index(drop=True)\n",
    "aggregated['snr'] = aggregated['mean'] / aggregated['std']\n",
    "aggregated['domain'] = aggregated['domain'].apply(lambda x: clean_label(x))\n",
    "aggregated.round(2)"
   ],
   "id": "4fff31de9483a259",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'domain'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/LocResearch/rename/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'domain'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[86], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m aggregated \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mgroupby(by\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdomain\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjsd\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39magg([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      8\u001B[0m aggregated[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msnr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m aggregated[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m/\u001B[39m aggregated[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 9\u001B[0m aggregated[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdomain\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43maggregated\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdomain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: clean_label(x))\n\u001B[1;32m     10\u001B[0m aggregated\u001B[38;5;241m.\u001B[39mround(\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/LocResearch/rename/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Documents/LocResearch/rename/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'domain'"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T21:18:10.845960Z",
     "start_time": "2024-11-25T21:18:10.836685Z"
    }
   },
   "cell_type": "code",
   "source": "aggregated",
   "id": "c66144a928ea0486",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                               domain      mean       std    median        snr\n",
       "0             america_and_its_history  0.138969  0.107668  0.180303   1.290711\n",
       "1                  crime_and_policing  0.196035  0.087087  0.183379   2.251035\n",
       "2                      foreign_policy  0.175533  0.077495  0.146840   2.265089\n",
       "3   gender_family_reproductive_issues  0.258828  0.095451  0.252513   2.711634\n",
       "4               gender_identity_sexor  0.417215  0.026883  0.427532  15.519771\n",
       "5                     govt_scope_role  0.338126  0.193135  0.404391   1.750722\n",
       "6                                guns  0.527802  0.009992  0.527915  52.824463\n",
       "7                         immigration  0.348030  0.102963  0.403569   3.380136\n",
       "8                  race_and_ethnicity  0.390888  0.113152  0.383105   3.454548\n",
       "9                     religous_values  0.218349  0.051454  0.218349   4.243548\n",
       "10                  social_safety_net  0.296738  0.162006  0.358519   1.831641"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>snr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>america_and_its_history</td>\n",
       "      <td>0.138969</td>\n",
       "      <td>0.107668</td>\n",
       "      <td>0.180303</td>\n",
       "      <td>1.290711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crime_and_policing</td>\n",
       "      <td>0.196035</td>\n",
       "      <td>0.087087</td>\n",
       "      <td>0.183379</td>\n",
       "      <td>2.251035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foreign_policy</td>\n",
       "      <td>0.175533</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.146840</td>\n",
       "      <td>2.265089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_family_reproductive_issues</td>\n",
       "      <td>0.258828</td>\n",
       "      <td>0.095451</td>\n",
       "      <td>0.252513</td>\n",
       "      <td>2.711634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender_identity_sexor</td>\n",
       "      <td>0.417215</td>\n",
       "      <td>0.026883</td>\n",
       "      <td>0.427532</td>\n",
       "      <td>15.519771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>govt_scope_role</td>\n",
       "      <td>0.338126</td>\n",
       "      <td>0.193135</td>\n",
       "      <td>0.404391</td>\n",
       "      <td>1.750722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guns</td>\n",
       "      <td>0.527802</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.527915</td>\n",
       "      <td>52.824463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>immigration</td>\n",
       "      <td>0.348030</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.403569</td>\n",
       "      <td>3.380136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>race_and_ethnicity</td>\n",
       "      <td>0.390888</td>\n",
       "      <td>0.113152</td>\n",
       "      <td>0.383105</td>\n",
       "      <td>3.454548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>religous_values</td>\n",
       "      <td>0.218349</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.218349</td>\n",
       "      <td>4.243548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>social_safety_net</td>\n",
       "      <td>0.296738</td>\n",
       "      <td>0.162006</td>\n",
       "      <td>0.358519</td>\n",
       "      <td>1.831641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c21f557bbb7aef6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
